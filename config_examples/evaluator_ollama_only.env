# 聊天和嵌入模型配置 - 纯Ollama (Chat + Embeddings)
# 复制到项目根目录并重命名为 .env.local.evaluator

# Ollama Chat模型配置
CHAT_API_KEY=  # Ollama本地服务不需要API key
CHAT_BASE_URL=http://localhost:11434/v1
CHAT_MODEL=qwen2.5-coder:0.5b-instruct-q4_K_S

# Ollama Embeddings配置
EMBEDDING_BASE_URL=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text:latest
EMBEDDING_API_KEY=ollama

# 使用说明:
# 1. 安装并启动Ollama: https://ollama.ai/
# 2. 拉取Chat模型: ollama pull qwen2.5-coder:0.5b-instruct-q4_K_S
# 3. 拉取嵌入模型: ollama pull nomic-embed-text:latest
# 4. 确保Ollama服务运行在 http://localhost:11434

# 可选的Chat模型:
# - qwen2.5-coder:0.5b-instruct-q4_K_S (轻量级)
# - deepseek-r1:1.5b (推理能力强)
# - llama3.2:3b (通用性好)

# 注意: 纯Ollama配置可能评价质量不如商业API
